{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ITensors.NDTensors\n",
    "using ITensors\n",
    "using LinearAlgebra\n",
    "using PyPlot\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension of the qr decomposition of ITensors to Blocksparse matrices and therefore to QNITensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qr_small (generic function with 3 methods)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function qr_small(T::BlockSparseTensor{ElT,2,StoreT,IndsT}; kwargs...) where{ElT, StoreT,IndsT}\n",
    "    Qs = Vector{DenseTensor{ElT,2}}(undef, nnzblocks(T))\n",
    "    Rs = Vector{DenseTensor{ElT,2}}(undef, nnzblocks(T))\n",
    "    \n",
    "    for (jj,b) in enumerate(eachnzblock(T))\n",
    "        blockT = blockview(T,b)\n",
    "        QRb = qr(blockT; kwargs...)\n",
    "        \n",
    "        if(isnothing(QRb))\n",
    "            return nothing\n",
    "        end\n",
    "        \n",
    "        Q, R   = QRb\n",
    "        Qs[jj] = Q\n",
    "        Rs[jj] = R\n",
    "        \n",
    "    end   \n",
    "    \n",
    "    # getting total number of blocks\n",
    "    nnzblocksT = nnzblocks(T)\n",
    "    nzblocksT  = nzblocks(T)\n",
    "    \n",
    "    nb1_lt_nb2 = (\n",
    "             nblocks(T)[1] < nblocks(T)[2] ||\n",
    "            (nblocks(T)[1] == nblocks(T)[2] && dim(T, 1) < dim(T, 2))\n",
    "          )\n",
    "\n",
    "    # setting the right index of the Q isometry, this should be\n",
    "    # the smaller index of the two indices of of T\n",
    "    qindl = ind(T,1)\n",
    "    if nb1_lt_nb2\n",
    "        qindr = sim(ind(T, 1))\n",
    "    else\n",
    "        qindr = sim(ind(T, 2))\n",
    "    end\n",
    "    \n",
    "    # can qindr have more blocks than T?\n",
    "    if nblocks(qindr) > nnzblocksT\n",
    "        resize!(qindr, nnzblocksT)\n",
    "    end\n",
    "    \n",
    "    for n in 1:nnzblocksT\n",
    "        q_dim_red = minimum(dims(Rs[n]))\n",
    "        NDTensors.setblockdim!(qindr, q_dim_red, n)\n",
    "    end\n",
    "    \n",
    "    # correcting the direction of the arrow\n",
    "    # since qind2r is basically a copy of qind1r\n",
    "    # if one have to be corrected the other one \n",
    "    # should also be corrected\n",
    "    if(dir(qindr) != dir(qindl))\n",
    "        qindr = dag(qindr)\n",
    "    end\n",
    "    \n",
    "    indsQ = setindex(inds(T), dag(qindr), 2)\n",
    "    \n",
    "    # R left index\n",
    "    rindl = qindr\n",
    "    rindr = ind(T,2)\n",
    "    \n",
    "    #if(dir(rindl) != dir(rindr))\n",
    "    #    rindl = dag(rindl)\n",
    "    #end\n",
    "    \n",
    "    indsR = setindex(inds(T), qindr, 1)\n",
    "    \n",
    "    nzblocksQ = Vector{Block{2}}(undef, nnzblocksT)\n",
    "    nzblocksR = Vector{Block{2}}(undef, nnzblocksT)\n",
    "    \n",
    "    for n in 1:nnzblocksT\n",
    "        blockT = nzblocksT[n]\n",
    "        \n",
    "        blockQ = (blockT[1], UInt(n))\n",
    "        nzblocksQ[n] = blockQ\n",
    "       \n",
    "        blockR = (blockT[2], UInt(n))\n",
    "        nzblocksR[n] = blockR\n",
    "    end\n",
    "    \n",
    "    Q = BlockSparseTensor(ElT, undef, nzblocksQ, indsQ)\n",
    "    R = BlockSparseTensor(ElT, undef, nzblocksR, indsR)\n",
    "    \n",
    "    \n",
    "    for n in 1:nnzblocksT\n",
    "        Qb, Rb = Qs[n], Rs[n]\n",
    "        blockQ = nzblocksQ[n]\n",
    "        blockR = nzblocksR[n]\n",
    "        \n",
    "         if VERSION < v\"1.5\"\n",
    "            # In v1.3 and v1.4 of Julia, Ub has\n",
    "            # a very complicated view wrapper that\n",
    "            # can't be handled efficiently\n",
    "            Qb = copy(Qb)\n",
    "            Rb  = copy(Vb)\n",
    "        end\n",
    "        \n",
    "        blockview(Q, blockQ) .= Qb\n",
    "        blockview(R, blockR) .= Rb\n",
    "    end\n",
    "    \n",
    "    # correcting the fluxes of the \n",
    "    # two tensors, such that \n",
    "    # Q has 0 flux for all blocks\n",
    "    # and R has the total flux of the system\n",
    "    for b in nzblocks(Q)\n",
    "        i1 = inds(Q)[1]\n",
    "        i2 = inds(Q)[2]\n",
    "        r1 = inds(R)[1]\n",
    "        newqn = -dir(i2) * flux(i1 => Block(b[1]))\n",
    "        ITensors.setblockqn!(i2, newqn, b[2])\n",
    "        ITensors.setblockqn!(r1, newqn, b[2])\n",
    "    end\n",
    "    \n",
    "    return Q, R\n",
    "end\n",
    "\n",
    "function qr_small(T::BlockSparseTensor{ElT,1,StoreT,IndsT}; kwargs...) where{ElT,StoreT,IndsT}\n",
    "    Qs = Vector{DenseTensor{ElT,2}}(undef, nnzblocks(T))\n",
    "    Rs = Vector{DenseTensor{ElT,1}}(undef, nnzblocks(T))\n",
    "\n",
    "    for (jj,b) in enumerate(eachnzblock(T))\n",
    "        blockT = blockview(T,b)\n",
    "        blockT = reshape(blockT, dim(blockT), 1)\n",
    "        QRb = qr(blockT; kwargs...)\n",
    "        \n",
    "        if(isnothing(QRb))\n",
    "            return nothing\n",
    "        end\n",
    "        \n",
    "        Q, R   = QRb\n",
    "        Qs[jj] = Q\n",
    "        Rs[jj] = reshape(R,dim(R))\n",
    "    end   \n",
    "    \n",
    "    # getting total number of blocks\n",
    "    nnzblocksT = nnzblocks(T)\n",
    "    nzblocksT  = nzblocks(T)\n",
    "\n",
    "    # setting the right index of the Q isometry, this should be\n",
    "    # the smaller index of the two indices of of T\n",
    "    qindl = ind(T,1)\n",
    "    qindr = sim(qindl)\n",
    "    \n",
    "    # can qindr have more blocks than T?\n",
    "    if nblocks(qindr) > nnzblocksT\n",
    "        resize!(qindr, nnzblocksT)\n",
    "    end\n",
    "    \n",
    "    for n in 1:nnzblocksT\n",
    "        q_dim_red = minimum(dims(Rs[n]))\n",
    "        NDTensors.setblockdim!(qindr, q_dim_red, n)\n",
    "    end\n",
    "    \n",
    "    # correcting the direction of the arrow\n",
    "    # since qind2r is basically a copy of qind1r\n",
    "    # if one have to be corrected the other one \n",
    "    # should also be corrected\n",
    "    if(dir(qindr) != dir(qindl))\n",
    "        qindr = dag(qindr)\n",
    "    end\n",
    "    \n",
    "    indsQ = (qindl, dag(qindr))\n",
    "    \n",
    "    # R left index\n",
    "    rindl = qindr\n",
    "    #rindr = ind(T,2)\n",
    "    \n",
    "    #if(dir(rindl) != dir(rindr))\n",
    "    #    rindl = dag(rindl)\n",
    "    #end\n",
    "    \n",
    "    indsR = setindex(inds(T)[1:1], rindl, 1)\n",
    "    \n",
    "    nzblocksQ = Vector{Block{2}}(undef, nnzblocksT)\n",
    "    nzblocksR = Vector{Block{1}}(undef, nnzblocksT)\n",
    "    \n",
    "    for n in 1:nnzblocksT\n",
    "        blockT = nzblocksT[n]\n",
    "        \n",
    "        blockQ = (blockT[1], UInt(n))\n",
    "        nzblocksQ[n] = blockQ\n",
    "       \n",
    "        blockR = (UInt(n), )\n",
    "        nzblocksR[n] = blockR\n",
    "    end\n",
    "    \n",
    "    Q = BlockSparseTensor(ElT, undef, nzblocksQ, indsQ)\n",
    "    R = BlockSparseTensor(ElT, undef, nzblocksR, indsR)\n",
    "    \n",
    "    \n",
    "    for n in 1:nnzblocksT\n",
    "        Qb, Rb = Qs[n], Rs[n]\n",
    "        blockQ = nzblocksQ[n]\n",
    "        blockR = nzblocksR[n]\n",
    "        \n",
    "         if VERSION < v\"1.5\"\n",
    "            # In v1.3 and v1.4 of Julia, Ub has\n",
    "            # a very complicated view wrapper that\n",
    "            # can't be handled efficiently\n",
    "            Qb = copy(Qb)\n",
    "            Rb  = copy(Vb)\n",
    "        end\n",
    "        \n",
    "        blockview(Q, blockQ) .= Qb\n",
    "        blockview(R, blockR) .= Rb\n",
    "    end\n",
    "    \n",
    "    # correcting the fluxes of the \n",
    "    # two tensors, such that \n",
    "    # Q has 0 flux for all blocks\n",
    "    # and R has the total flux of the system\n",
    "    for b in nzblocks(Q)\n",
    "        i1 = inds(Q)[1]\n",
    "        i2 = inds(Q)[2]\n",
    "        r1 = inds(R)[1]\n",
    "        newqn = -dir(i2) * flux(i1 => Block(b[1]))\n",
    "        ITensors.setblockqn!(i2, newqn, b[2])\n",
    "        ITensors.setblockqn!(r1, newqn, b[2])\n",
    "    end\n",
    "    \n",
    "    return Q, R\n",
    "end\n",
    "\n",
    "\n",
    "function qr_small(A::ITensor, Linds...; kwargs...)\n",
    "    tags::TagSet = get(kwargs, :tags, \"Link,qr\")\n",
    "    \n",
    "    Lis = commoninds(A, IndexSet(Linds...))\n",
    "    Ris = uniqueinds(A, Lis)\n",
    "    \n",
    "    if length(Lis) == 0 && length(Ris) == 0\n",
    "        error(\n",
    "                \"In `qr`, the left and right indices are empty (the indices of `A` are ($(inds(A))), but the input indices are ($Lis)). For now, this is not supported. You may have accidentally input the wrong indices.\",\n",
    "            )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    CL = combiner(Lis...)\n",
    "    CR = combiner(Ris...)\n",
    "    \n",
    "    AC = A * CR * CL\n",
    "    \n",
    "    if(length(Lis) == 0)\n",
    "        At = tensor(AC)\n",
    "        # build trivial leg\n",
    "        qtriv = zero(qn(inds(AC)[1], Block(1)))\n",
    "        qidx  = Index(qtriv => 1; tags = tags, dir = ITensors.In)\n",
    "        Q  = delta(qidx)\n",
    "        \n",
    "        nzblocksR = Vector{Block{2}}(undef, nnzblocks(AC))\n",
    "        for (jj,b) in enumerate(eachnzblock(At))\n",
    "            blockR = (UInt(1), b[1])\n",
    "            nzblocksR[jj] = blockR\n",
    "        end\n",
    "        Rt = BlockSparseTensor(eltype(At), undef, nzblocksR, (dag(qidx),inds(AC)...))\n",
    "        for (jj,b) in enumerate(eachnzblock(At))\n",
    "            ACB = blockview(At,b)\n",
    "            if VERSION < v\"1.5\"\n",
    "                # In v1.3 and v1.4 of Julia, Ub has\n",
    "                # a very complicated view wrapper that\n",
    "                # can't be handled efficiently\n",
    "                ACB = copy(ACB)\n",
    "            end \n",
    "            ACB = reshape(ACB,(1,dim(ACB)))\n",
    "            blockR = nzblocksR[jj]\n",
    "            blockview(Rt, blockR) .= ACB\n",
    "        end\n",
    "        RC = itensor(Rt)\n",
    "        \n",
    "        R = RC*dag(CR)\n",
    "        return Q,R, qidx\n",
    "    elseif(length(Ris) == 0)\n",
    "        QRT = qr_small(tensor(AC); kwargs...)\n",
    "    else\n",
    "        cL = combinedind(CL)\n",
    "        cR = combinedind(CR)\n",
    "    \n",
    "        if inds(AC) != IndexSet(cL, cR)\n",
    "            AC = permute(AC, cL, cR)\n",
    "        end\n",
    "    \n",
    "        QRT = qr_small(tensor(AC); kwargs...)\n",
    "    end\n",
    "    \n",
    "    \n",
    "    if isnothing(QRT)\n",
    "        return nothing\n",
    "    end\n",
    "    QT, RT = QRT\n",
    "    QC, RC = itensor(QT), itensor(RT)\n",
    "    \n",
    "    qidx  = commonind(QC,RC)\n",
    "    \n",
    "    \n",
    "    Q = QC * dag(CL)\n",
    "    R = RC * dag(CR)\n",
    "    \n",
    "    settags!(Q, tags, qidx)\n",
    "    settags!(R,  tags, qidx)\n",
    "    qidx = settags(qidx, tags)\n",
    "    \n",
    "    return Q, R, qidx\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requesting a full qr decomposition for dense tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qr_full_dense (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function qr_full(T::DenseTensor{ElT,2,IndsT}; kwargs...) where{ElT,IndsT}\n",
    "    positive = get(kwargs, :positive, false)\n",
    "    if(positive)\n",
    "        error(\"Not implemented\")\n",
    "    else\n",
    "        #QM, RM = qr(matrix(T))\n",
    "        F = qr(matrix(T))\n",
    "    end\n",
    "    \n",
    "    # converting QM to Q1 and Q2\n",
    "    # getting the correct dimensions\n",
    "    dim1  = dim(T,1)\n",
    "    dim2  = dim(T,2)\n",
    "    q_dim = size(F.Q,1)\n",
    "    q_dim_red = min(dim1,dim2)\n",
    "    \n",
    "    # getting the new index objects with correct dimensions.\n",
    "    # the right index of the orthogonal Q2 part will be added a `ortho` tag\n",
    "    q,r = inds(T)\n",
    "    \n",
    "    q_red   = eltype(IndsT)(q_dim_red)\n",
    "    q_ortho = eltype(IndsT)(q_dim - q_dim_red)\n",
    "    #q_red   = Index(q_dim_red, tags(q))\n",
    "    #q_ortho = Index(q_dim - q_dim_red, tags(q))\n",
    "    #q_ortho = addtags(q_ortho,\"ortho\")\n",
    "    \n",
    "    # Indecies of the Q1,Q2 and R Tensors\n",
    "    Q1inds = IndsT((ind(T, 1), q_red))\n",
    "    Q2inds = IndsT((ind(T, 1), q_ortho))\n",
    "    Rinds  = IndsT((q_red, ind(T, 2)))\n",
    "    \n",
    "    # reading out the matrices\n",
    "    QM = F.Q*Matrix{ElT}(I,size(F.Q))\n",
    "    #Q1M = @view QM[:,1:q_dim_red]\n",
    "    #Q2M = @view QM[:,q_dim_red+1:end]\n",
    "    \n",
    "    Q1 = tensor(Dense(vec(QM[:,1:q_dim_red])), Q1inds)\n",
    "    Q2 = tensor(Dense(vec(QM[:,q_dim_red+1:end])), Q2inds)\n",
    "    #RM = F.R\n",
    "    R  = tensor(Dense(vec(F.R)), Rinds)\n",
    "    return Q1,Q2,R\n",
    "end\n",
    "\n",
    "function qr_full(\n",
    "    T::DenseTensor{<:Number,N,IndsT}, Lpos::NTuple{NL,Int}, Rpos::NTuple{NR,Int}; kwargs...\n",
    "    ) where{N,IndsT,NL,NR}\n",
    "    \n",
    "    \n",
    "    M = NDTensors.permute_reshape(T,Lpos,Rpos)\n",
    "    Q1M, Q2M, RM  = qr_full(M; kwargs...)\n",
    "    qn = ind(Q1M,2)\n",
    "    qo = ind(Q2M,2)\n",
    "    r  = ind(RM,1)\n",
    "    Linds = NDTensors.similartype(IndsT, Val{NL})(ntuple(i -> inds(T)[Lpos[i]], Val(NL)))\n",
    "    Q1inds = NDTensors.push(Linds,qn)\n",
    "    Q2inds = NDTensors.push(Linds,qo)\n",
    "    Q1 = reshape(Q1M,Q1inds)\n",
    "    Q2 = reshape(Q2M,Q2inds)\n",
    "    Rinds = NDTensors.similartype(IndsT, Val{NR})(ntuple(i -> inds(T)[Rpos[i]], Val(NR)))\n",
    "    Rinds = NDTensors.pushfirst(Rinds,r)\n",
    "    R = reshape(RM,Rinds)\n",
    "    return Q1, Q2, R\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function qr_full_dense(A::ITensor, Linds...; kwargs...)\n",
    "    tags::TagSet = get(kwargs, :tags, \"Link,qr\")\n",
    "    Lis = commoninds(A, IndexSet(Linds...))\n",
    "    Ris = uniqueinds(A,Lis)\n",
    "    \n",
    "    Lpos, Rpos = NDTensors.getperms(inds(A), Lis, Ris)\n",
    "    Q1T, Q2T, RT = qr_full(tensor(A), Lpos, Rpos; kwargs...)\n",
    "    Q1, Q2, R = itensor(Q1T), itensor(Q2T), itensor(RT)\n",
    "    qidx = commonind(Q1,R)\n",
    "    lidx = uniqueinds(Q1,qidx)\n",
    "    settags!(Q1,tags,qidx) \n",
    "    settags!(R ,tags,qidx)\n",
    "    qidx = settags(qidx,tags)\n",
    "\n",
    "    tags = ITensors.addtags(tags,\"ortho\")\n",
    "    qoidx = uniqueinds(Q2,lidx)\n",
    "    settags!(Q2,tags,qoidx)\n",
    "    return Q1, Q2, R, qidx,qoidx\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requesting a full qr decomposition for block sparse (QN ITensors) tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qr_full_qn (generic function with 1 method)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function qr_full(T::BlockSparseTensor{ElT,1,StoreT, IndsT}; kwargs...) where{ElT, StoreT, IndsT}\n",
    "    # blocks of the tensor T and number of blocks\n",
    "    nnzblocksT = nnzblocks(T)\n",
    "    nzblocksT  = nzblocks(T)\n",
    "    \n",
    "    # setting the right index of the Q isometry, this should be\n",
    "    # the smaller index of the two indices of of T\n",
    "    qindl  = ind(T,1)\n",
    "    qind1r = sim(qindl)\n",
    "    \n",
    "    \n",
    "    if nblocks(qind1r) > nnzblocksT\n",
    "        resize!(qind1r, nnzblocksT)\n",
    "    end\n",
    "    \n",
    "    # correcting the direction of the arrow\n",
    "    # since qind2r is basically a copy of qind1r\n",
    "    # if one have to be corrected the other one \n",
    "    # should also be corrected\n",
    "    if(dir(qind1r) == dir(qindl))\n",
    "        qind1r = dag(qind1r)\n",
    "    end\n",
    "    \n",
    "    # qr decomposition of the different original blocks\n",
    "    Q1s = Vector{DenseTensor{ElT,2}}(undef, nnzblocksT)\n",
    "    Q2s = Vector{DenseTensor{ElT,2}}(undef, nnzblocksT)\n",
    "    Rs  = Vector{DenseTensor{ElT,1}}(undef, nnzblocksT)\n",
    "    \n",
    "    \n",
    "    for (jj,b) in enumerate(eachnzblock(T))\n",
    "        blockT = blockview(T,b)\n",
    "        blockT = reshape(blockT, dim(blockT), 1)\n",
    "        \n",
    "        QRb    = qr_full(blockT)\n",
    "        \n",
    "        if(isnothing(QRb))\n",
    "            return nothing\n",
    "        end\n",
    "        \n",
    "        Q1,Q2,R = QRb\n",
    "        Q1s[jj] = Q1\n",
    "        Q2s[jj] = Q2\n",
    "        R = reshape(R, dim(R))\n",
    "        Rs[jj]  = R\n",
    "    end\n",
    "    \n",
    "    for n in 1:nnzblocksT\n",
    "        q_dim_red = minimum(dims(Rs[n]))\n",
    "        NDTensors.setblockdim!(qind1r, q_dim_red, n)\n",
    "    end\n",
    "    \n",
    "    indsQ1 = (qindl, qind1r)\n",
    "    \n",
    "    \n",
    "    # R left index\n",
    "    rindl = dag(qind1r)\n",
    "    indsR = setindex(inds(T)[1:1], rindl, 1)\n",
    "\n",
    "    nzblocksQ1 = Vector{Block{2}}(undef, nnzblocksT)\n",
    "    nzblocksR  = Vector{Block{1}}(undef, nnzblocksT)\n",
    "\n",
    "    for n in 1:nnzblocksT\n",
    "        blockT = nzblocksT[n]\n",
    "        \n",
    "        blockQ = (blockT[1], UInt(n))\n",
    "        nzblocksQ1[n] = blockQ\n",
    "    \n",
    "        blockR = (UInt(n), )\n",
    "        nzblocksR[n] = blockR\n",
    "    end\n",
    "    \n",
    "    Q1 = BlockSparseTensor(ElT, undef, nzblocksQ1, indsQ1)\n",
    "    R  = BlockSparseTensor(ElT, undef, nzblocksR, indsR)\n",
    "\n",
    "    \n",
    "    for n in 1:nnzblocksT\n",
    "        Q1b, Rb = Q1s[n], Rs[n]\n",
    "        blockQ1 = nzblocksQ1[n]\n",
    "        blockR  = nzblocksR[n]\n",
    "        \n",
    "        if VERSION < v\"1.5\"\n",
    "            # In v1.3 and v1.4 of Julia, Ub has\n",
    "            # a very complicated view wrapper that\n",
    "            # can't be handled efficiently\n",
    "            Q1b = copy(Q1b)\n",
    "            Rb  = copy(Vb) \n",
    "        end\n",
    "        \n",
    "        blockview(Q1, blockQ1) .= Q1b\n",
    "        blockview(R,  blockR)  .= Rb\n",
    "    end\n",
    "    \n",
    "    \n",
    "    # correcting the fluxes of the \n",
    "    # two tensors, such that \n",
    "    # Q has 0 flux for all blocks\n",
    "    # and R has the total flux of the system\n",
    "    for b in nzblocks(Q1)\n",
    "        i1 = inds(Q1)[1]\n",
    "        i2 = inds(Q1)[2]\n",
    "        r1 = inds(R)[1]\n",
    "        newqn = -dir(i2) * flux(i1 => Block(b[1]))\n",
    "        ITensors.setblockqn!(i2, newqn, b[2])\n",
    "        ITensors.setblockqn!(r1, newqn, b[2])\n",
    "    end\n",
    "        \n",
    "    \n",
    "    #### up to here, Q1 and R are finished builded\n",
    "    ### Now the next step is to determine \n",
    "    ### wether there are possible unadressed qn \n",
    "    ### with the correct flux\n",
    "    \n",
    "    # the flux of Q1 should be zero through the construction\n",
    "    # therefore we need just to find possible blocks\n",
    "    # which would be probl. available in the full (qindl,dag(qindl))\n",
    "    # matrix with 0 flux but are not present in the Q1 matrix\n",
    "    # these have to be filled in the Q2 matrix\n",
    "    \n",
    "    imgsp = space(qindl)\n",
    "    q1sp  = space(qind1r)\n",
    "    q1q   = qn.(q1sp)\n",
    "    q1d   = blockdim.(q1sp)\n",
    "    \n",
    "    orthosp = Vector{Pair{QN,Int}}()\n",
    "    \n",
    "    # imgsp is a Vector{Pair{QN, Int}}, such that\n",
    "    # we can unpack it to get the qn and dimension directly\n",
    "    exists_in_both = Vector{Int}() # list of tracking blocks existing in both tensors\n",
    "    for (spq, spd) in imgsp\n",
    "        # now test it the qn is present in the q1q array\n",
    "        # holding all target qn numbers of the Q1 tensor\n",
    "        if(spq in q1q)\n",
    "            idx = findfirst(x -> x == spq, q1q)\n",
    "            # check if it has the full dimensionality\n",
    "            if(q1d[idx] < spd)\n",
    "                push!(orthosp, spq => spd - q1d[idx])\n",
    "                push!(exists_in_both,length(orthosp))\n",
    "            end\n",
    "        else\n",
    "            push!(orthosp, spq => spd)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # generating the index for the orthogonal space\n",
    "    qortags = addtags(tags(qind1r), \"ortho\")\n",
    "    qind2r  = Index(orthosp, qortags; dir = dir(qind1r))\n",
    "    \n",
    "    # savety check, the dimensionality should add up\n",
    "    # to the total dimensionality of the left leg\n",
    "    @assert dim(qind1r) + dim(qind2r) == dim(qindl)\n",
    "    \n",
    "    indsQ2 = (qindl, qind2r)\n",
    "    \n",
    "    # now the different blocks of the Q2 tensor have to be created\n",
    "    # their size has to be the same as the number of blocks in the\n",
    "    # right Index\n",
    "    nzblocksQ2 = Vector{Block{2}}(undef, nblocks(qind2r))\n",
    "    \n",
    "    # go through all possible targets\n",
    "    for (jj, img) in enumerate(orthosp)\n",
    "        imgq = qn(img)\n",
    "        blockQ2L = ITensors.block(first, qindl, imgq)\n",
    "        blockQ2R = ITensors.block(first, qind2r, dir(qind2r)*imgq)\n",
    "        nzblocksQ2[jj] = (blockQ2L,blockQ2R)\n",
    "    end\n",
    "    \n",
    "    # now build the Q2 tensor\n",
    "    Q2 = BlockSparseTensor(ElT, undef, nzblocksQ2, indsQ2)\n",
    "   \n",
    "    # now looping through all blocks in the Q2 matrix\n",
    "    for (jj, blockQ2) in enumerate(nzblocksQ2)\n",
    "        if(jj in exists_in_both)\n",
    "            qr = qn(qind2r, blockQ2[2]) # qn of the block\n",
    "            # getting the block for this qn in the qind1r index\n",
    "            blockQ1R = ITensors.block(first, qind1r, dir(qind1r)*qr)\n",
    "            # getting the original index for that transition\n",
    "            # this encodes the index in the list of dense qr decompositions\n",
    "            idx = Int(blockQ1R[1])\n",
    "            Q2b = Q2s[idx]\n",
    "            \n",
    "        else    \n",
    "            blkdim = blockdim(orthosp[jj])\n",
    "            Q2b = Matrix{ElT}(I,blkdim, blkdim)\n",
    "        end\n",
    "        blockview(Q2, blockQ2) .= Q2b\n",
    "    end\n",
    "    \n",
    "    return Q1,Q2,R\n",
    "end\n",
    "\n",
    "function qr_full(T::BlockSparseTensor{ElT,2,StoreT,IndsT}; kwargs...) where{ElT, StoreT,IndsT}\n",
    "    # blocks of the tensor T and number of blocks\n",
    "    nnzblocksT = nnzblocks(T)\n",
    "    nzblocksT  = nzblocks(T)\n",
    "\n",
    "\n",
    "    # getting the large index\n",
    "    nb1_lt_nb2 = (\n",
    "             nblocks(T)[1] < nblocks(T)[2] ||\n",
    "            (nblocks(T)[1] == nblocks(T)[2] && dim(T, 1) ≤ dim(T, 2))\n",
    "              )\n",
    "\n",
    "    # setting the right index of the Q isometry, this should be\n",
    "    # the smaller index of the two indices of of T\n",
    "    # while for the orthogonal complement we choose the large\n",
    "    # index as right index\n",
    "    qindl = ind(T,1)\n",
    "    if nb1_lt_nb2\n",
    "        # doing a fast exit here \n",
    "        #Q1,R = qr_small(T)\n",
    "        Q1,R = qr_small(T)\n",
    "        Q2 = nothing\n",
    "        return Q1,Q2,R\n",
    "        #qind1r = sim(ind(T, 1))\n",
    "        #qind2r = sim(ind(T, 2))\n",
    "    else\n",
    "        qind1r    = sim(ind(T, 2))\n",
    "    end\n",
    "    \n",
    "    if nblocks(qind1r) > nnzblocksT\n",
    "        resize!(qind1r, nnzblocksT)\n",
    "    end\n",
    "    \n",
    "    # correcting the direction of the arrow\n",
    "    # since qind2r is basically a copy of qind1r\n",
    "    # if one have to be corrected the other one \n",
    "    # should also be corrected\n",
    "    if(dir(qind1r) == dir(qindl))\n",
    "        qind1r = dag(qind1r)\n",
    "    end\n",
    "\n",
    "\n",
    "    # qr decomposition of the different original blocks\n",
    "    Q1s = Vector{DenseTensor{ElT,2}}(undef, nnzblocksT)\n",
    "    Q2s = Vector{DenseTensor{ElT,2}}(undef, nnzblocksT)\n",
    "    Rs  = Vector{DenseTensor{ElT,2}}(undef, nnzblocksT)\n",
    "\n",
    "    for (jj,b) in enumerate(eachnzblock(T))\n",
    "        blockT = blockview(T,b)\n",
    "        QRb    = qr_full(blockT)\n",
    "        \n",
    "        if(isnothing(QRb))\n",
    "            return nothing\n",
    "        end\n",
    "        \n",
    "        Q1,Q2,R = QRb\n",
    "        Q1s[jj] = Q1\n",
    "        Q2s[jj] = Q2\n",
    "        Rs[jj]  = R\n",
    "    end\n",
    "\n",
    "    for n in 1:nnzblocksT\n",
    "        q_dim_red = minimum(dims(Rs[n]))\n",
    "        NDTensors.setblockdim!(qind1r, q_dim_red, n)\n",
    "    end\n",
    "\n",
    "    indsQ1 = setindex(inds(T), qind1r, 2)\n",
    "    # R left index\n",
    "    rindl = dag(qind1r)\n",
    "    indsR = setindex(inds(T), rindl, 1)\n",
    "\n",
    "    nzblocksQ1 = Vector{Block{2}}(undef, nnzblocksT)\n",
    "    nzblocksR  = Vector{Block{2}}(undef, nnzblocksT)\n",
    "\n",
    "    for n in 1:nnzblocksT\n",
    "        blockT = nzblocksT[n]\n",
    "        blockQ = (blockT[1], UInt(n))\n",
    "        nzblocksQ1[n] = blockQ\n",
    "    \n",
    "        blockR = (blockT[2], UInt(n))\n",
    "        nzblocksR[n] = blockR\n",
    "    end\n",
    "\n",
    "\n",
    "    Q1 = BlockSparseTensor(ElT, undef, nzblocksQ1, indsQ1)\n",
    "    R  = BlockSparseTensor(ElT, undef, nzblocksR, indsR)\n",
    "\n",
    "    for n in 1:nnzblocksT\n",
    "        Q1b, Rb = Q1s[n], Rs[n]\n",
    "        blockQ1 = nzblocksQ1[n]\n",
    "        blockR  = nzblocksR[n]\n",
    "        \n",
    "        if VERSION < v\"1.5\"\n",
    "            # In v1.3 and v1.4 of Julia, Ub has\n",
    "            # a very complicated view wrapper that\n",
    "            # can't be handled efficiently\n",
    "            Q1b = copy(Q1b)\n",
    "            Rb  = copy(Vb) \n",
    "        end\n",
    "        \n",
    "        blockview(Q1, blockQ1) .= Q1b\n",
    "        blockview(R,  blockR)  .= Rb\n",
    "    end\n",
    "    \n",
    "        \n",
    "    # correcting the fluxes of the \n",
    "    # two tensors, such that \n",
    "    # Q has 0 flux for all blocks\n",
    "    # and R has the total flux of the system\n",
    "    for b in nzblocks(Q1)\n",
    "        i1 = inds(Q1)[1]\n",
    "        i2 = inds(Q1)[2]\n",
    "        r1 = inds(R)[1]\n",
    "        newqn = -dir(i2) * flux(i1 => Block(b[1]))\n",
    "        ITensors.setblockqn!(i2, newqn, b[2])\n",
    "        ITensors.setblockqn!(r1, newqn, b[2])\n",
    "    end\n",
    "    \n",
    "    #### up to here, Q1 and R are finished builded\n",
    "    ### Now the next step is to determine \n",
    "    ### wether there are possible unadressed qn \n",
    "    ### with the correct flux\n",
    "    \n",
    "    # the flux of Q1 should be zero through the construction\n",
    "    # therefore we need just to find possible blocks\n",
    "    # which would be probl. available in the full (qindl,dag(qindl))\n",
    "    # matrix with 0 flux but are not present in the Q1 matrix\n",
    "    # these have to be filled in the Q2 matrix\n",
    "    \n",
    "    imgsp = space(qindl)\n",
    "    q1sp  = space(qind1r)\n",
    "    q1q   = qn.(q1sp)\n",
    "    q1d   = blockdim.(q1sp)\n",
    "    \n",
    "    orthosp = Vector{Pair{QN,Int}}()\n",
    "    \n",
    "    # imgsp is a Vector{Pair{QN, Int}}, such that\n",
    "    # we can unpack it to get the qn and dimension directly\n",
    "    exists_in_both = Vector{Int}() # list of tracking blocks existing in both tensors\n",
    "    for (spq, spd) in imgsp\n",
    "        # now test it the qn is present in the q1q array\n",
    "        # holding all target qn numbers of the Q1 tensor\n",
    "        if(spq in q1q)\n",
    "            idx = findfirst(x -> x == spq, q1q)\n",
    "            # check if it has the full dimensionality\n",
    "            if(q1d[idx] < spd)\n",
    "                push!(orthosp, spq => spd - q1d[idx])\n",
    "                push!(exists_in_both,length(orthosp))\n",
    "            end\n",
    "        else\n",
    "            push!(orthosp, spq => spd)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # generating the index for the orthogonal space\n",
    "    qortags = addtags(tags(qind1r), \"ortho\")\n",
    "    qind2r  = Index(orthosp, qortags; dir = dir(qind1r))\n",
    "    \n",
    "    # savety check, the dimensionality should add up\n",
    "    # to the total dimensionality of the left leg\n",
    "    @assert dim(qind1r) + dim(qind2r) == dim(qindl)\n",
    "    \n",
    "    indsQ2 = setindex(inds(T), qind2r, 2)\n",
    "    \n",
    "    # now the different blocks of the Q2 tensor have to be created\n",
    "    # their size has to be the same as the number of blocks in the\n",
    "    # right Index\n",
    "    nzblocksQ2 = Vector{Block{2}}(undef, nblocks(qind2r))\n",
    "    \n",
    "    # go through all possible targets\n",
    "    for (jj, img) in enumerate(orthosp)\n",
    "        imgq = qn(img)\n",
    "        blockQ2L = ITensors.block(first, qindl, imgq)\n",
    "        blockQ2R = ITensors.block(first, qind2r, dir(qind2r)*imgq)\n",
    "        nzblocksQ2[jj] = (blockQ2L,blockQ2R)\n",
    "    end\n",
    "    \n",
    "    # now build the Q2 tensor\n",
    "    Q2 = BlockSparseTensor(ElT, undef, nzblocksQ2, indsQ2)\n",
    "   \n",
    "    # now looping through all blocks in the Q2 matrix\n",
    "    for (jj, blockQ2) in enumerate(nzblocksQ2)\n",
    "        if(jj in exists_in_both)\n",
    "            qr = qn(qind2r, blockQ2[2]) # qn of the block\n",
    "            # getting the block for this qn in the qind1r index\n",
    "            blockQ1R = ITensors.block(first, qind1r, dir(qind1r)*qr)\n",
    "            # getting the original index for that transition\n",
    "            # this encodes the index in the list of dense qr decompositions\n",
    "            idx = Int(blockQ1R[1])\n",
    "            Q2b = Q2s[idx]\n",
    "            \n",
    "        else    \n",
    "            blkdim = blockdim(orthosp[jj])\n",
    "            Q2b = Matrix{ElT}(I,blkdim, blkdim)\n",
    "        end\n",
    "        blockview(Q2, blockQ2) .= Q2b\n",
    "    end\n",
    "    \n",
    "    return Q1,Q2,R\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function qr_full_qn(A::ITensor, Linds...; kwargs...)\n",
    "    tags::TagSet = get(kwargs, :tags, \"Link,qr\")\n",
    "    \n",
    "    Lis = commoninds(A, IndexSet(Linds...))\n",
    "    Ris = uniqueinds(A, Lis)\n",
    "    \n",
    "    if length(Lis) == 0 && length(Ris) == 0\n",
    "        error(\n",
    "                \"In `qr`, the left and right indices are empty (the indices of `A` are ($(inds(A))), but the input indices are ($Lis)). For now, this is not supported. You may have accidentally input the wrong indices.\",\n",
    "            )\n",
    "    end\n",
    "    \n",
    "    \n",
    "    CL = combiner(Lis...)\n",
    "    CR = combiner(Ris...)\n",
    "    \n",
    "    AC = A * CR * CL\n",
    "    \n",
    "    if(length(Lis) == 0)\n",
    "        At = tensor(AC)\n",
    "        # build trivial leg\n",
    "        qtriv = zero(qn(inds(AC)[1], Block(1)))\n",
    "        qidx  = Index(qtriv => 1; tags = tags, dir = ITensors.In)\n",
    "        Q1    = delta(qidx)\n",
    "        \n",
    "        nzblocksR = Vector{Block{2}}(undef, nnzblocks(AC))\n",
    "        for (jj,b) in enumerate(eachnzblock(At))\n",
    "            blockR = (UInt(1), b[1])\n",
    "            nzblocksR[jj] = blockR\n",
    "        end\n",
    "        Rt = BlockSparseTensor(eltype(At), undef, nzblocksR, (dag(qidx),inds(AC)...))\n",
    "        for (jj,b) in enumerate(eachnzblock(At))\n",
    "            ACB = blockview(At,b)\n",
    "            if VERSION < v\"1.5\"\n",
    "                # In v1.3 and v1.4 of Julia, Ub has\n",
    "                # a very complicated view wrapper that\n",
    "                # can't be handled efficiently\n",
    "                ACB = copy(ACB)\n",
    "            end \n",
    "            ACB = reshape(ACB,(1,dim(ACB)))\n",
    "            blockR = nzblocksR[jj]\n",
    "            blockview(Rt, blockR) .= ACB\n",
    "        end\n",
    "        RC = itensor(Rt)\n",
    "        \n",
    "        R = RC*dag(CR)\n",
    "        return Q1, ITensor(0), R, qidx, nothing\n",
    "    elseif(length(Ris) == 0)\n",
    "        QRT = qr_full(tensor(AC); kwargs...)\n",
    "    else\n",
    "        cL = combinedind(CL)\n",
    "        cR = combinedind(CR)\n",
    "    \n",
    "        if inds(AC) != IndexSet(cL, cR)\n",
    "            AC = permute(AC, cL, cR)\n",
    "        end\n",
    "    \n",
    "        QRT = qr_full(tensor(AC); kwargs...)\n",
    "    end\n",
    "    \n",
    "    if isnothing(QRT)\n",
    "        return nothing\n",
    "    end\n",
    "    \n",
    "    Q1T, Q2T, RT = QRT\n",
    "    Q1C, RC = itensor(Q1T), itensor(RT)\n",
    "    \n",
    "    if(Q2T == nothing)\n",
    "        Q2 = ITensor(0)\n",
    "    else\n",
    "        Q2C = itensor(Q2T)\n",
    "    end\n",
    "    \n",
    "    qidx  = commonind(Q1C,RC)\n",
    "    lidx  = uniqueinds(Q1C,qidx)\n",
    "    if(!(Q2T == nothing))\n",
    "        qoidx = uniqueinds(Q2C,lidx)\n",
    "    end\n",
    "    \n",
    "    Q1 = Q1C * dag(CL)\n",
    "    if(!(Q2T == nothing))\n",
    "        Q2 = Q2C * dag(CL)\n",
    "    end\n",
    "    R  = RC  * dag(CR)\n",
    "    \n",
    "    \n",
    "    settags!(Q1, tags, qidx)\n",
    "    settags!(R,  tags, qidx)\n",
    "    qidx = settags(qidx, tags)\n",
    "    if(!(Q2T == nothing))\n",
    "        tags = ITensors.addtags(tags,\"ortho\")\n",
    "        settags!(Q2,tags,qoidx)\n",
    "        return Q1, Q2, R, qidx, qoidx\n",
    "    end\n",
    "    return Q1, Q2, R, qidx, nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the sparse/dense versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qr_full (generic function with 6 methods)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr_full(A::ITensor; kwargs...) = error(ITensors.noinds_error_message(\"qr\"))\n",
    "\n",
    "function qr_full(A::ITensor, Linds...; kwargs...)\n",
    "    if(hasqns(A))\n",
    "        return qr_full_qn(A, Linds...;kwargs...)\n",
    "    else\n",
    "        return qr_full_dense(A,Linds...;kwargs...)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing of the dense version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.972945262208935e-16\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "j1 = Index(4,\"j=1\")\n",
    "j2 = Index(4,\"j=2\")\n",
    "s  = Index(2,\"Site\")\n",
    "T  = randomITensor(j1,s,j2)\n",
    "\n",
    "Q1, Q2, R, qidx,qoidx = qr_full(T, (j1,s))\n",
    "println(norm(Q1*dag((Q2))))\n",
    "println(Q1*R ≈ T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the variance calculated using Hubigs scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calc_var (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function norm2(A::ITensor)\n",
    "    return real(scalar(A*dag(A)))\n",
    "end\n",
    "\n",
    "function calc_var(ψ, H; full_var = false)\n",
    "    if(full_var)\n",
    "        H2 = abs(inner(H,ψ,H,ψ))\n",
    "        E  = inner(ψ,H,ψ)\n",
    "        return H2 - E^2\n",
    "    end\n",
    "    \n",
    "    # copying the data\n",
    "    ψ_cp = copy(ψ)\n",
    "    orthogonalize!(ψ_cp,1)\n",
    "    nrm = norm(ψ_cp)\n",
    "    ψ_cp[1] = ψ_cp[1]/nrm\n",
    "    \n",
    "    L = length(ψ_cp)\n",
    "    \n",
    "    XF = Vector{ITensor}(undef,L-1)\n",
    "    \n",
    "    #println(ψ_cp[1])\n",
    "    # building the first left environment tensor\n",
    "    Li = ITensor(1)\n",
    "    Ri = ITensor(1)\n",
    "    \n",
    "    \n",
    "    XF   = Vector{ITensor}(undef, L)\n",
    "    #XF[1]   = ITensor(1)\n",
    "    rinds = commoninds(ψ_cp[1],ψ_cp[2])\n",
    "    linds = uniqueinds(ψ_cp[1],rinds)\n",
    "    for jj = 1:L - 1\n",
    "        T = ψ_cp[jj]\n",
    "        \n",
    "        A,F,R,qidx,qoidx = qr_full(T, linds; tags = \"Link,l=$(jj)\")\n",
    "    \n",
    "        ψ_cp[jj]    = A\n",
    "        ψ_cp[jj+1] *= R\n",
    "        \n",
    "        ITensors.setleftlim!(ψ_cp,jj)\n",
    "        ITensors.setrightlim!(ψ_cp,jj+2)\n",
    "        \n",
    "        XF[jj] = ((Li * A)*H[jj])\n",
    "        #XF[jj+1] = ((XF[jj] * A)*H[jj])*dag(prime(A))\n",
    "\n",
    "        Li = XF[jj]*dag(prime(A))\n",
    "        XF[jj]   *= dag(prime(F))\n",
    "        \n",
    "        linds = (qidx,inds(ψ_cp[jj+1],\"Site\")...)\n",
    "    end\n",
    "    A,F,R,qidx,qoidx = qr_full(ψ_cp[L], linds; tags = \"Link,l=$L\")\n",
    "    XF[L] = ((Li*ψ_cp[L])*H[L])*dag(prime(F))\n",
    "    res = norm2(XF[L])\n",
    "    #res = 0\n",
    "    \n",
    "    linds = commoninds(ψ_cp[L], ψ_cp[L - 1])\n",
    "    rinds = uniqueinds(ψ_cp[L], linds)\n",
    "    R_scale = ITensor(1)\n",
    "    for jj = L:-1:2\n",
    "        T = ψ_cp[jj]\n",
    "        B,G,R,qidx,qoidx = qr_full(T, rinds; tags = \"Link,l=$(jj - 1)\")\n",
    "        #B,R, qidx = qr_small(T, rinds; tags = \"Link,l=$(jj-1)\")\n",
    "\n",
    "        \n",
    "        ψ_cp[jj]      = B\n",
    "        ψ_cp[jj - 1] *= R\n",
    "        ITensors.setleftlim!(ψ_cp,jj - 2)\n",
    "        ITensors.setrightlim!(ψ_cp,jj)\n",
    "        \n",
    "        ###########################################################################################\n",
    "        #display(XF[jj]*T*H[jj])\n",
    "        #(((XF[jj]*T)*H[jj])*dag(prime(T)) * Ri) |> scalar |> display\n",
    "        #Ri = ((Ri*B)*H[jj])*dag(prime(B))        \n",
    "        \n",
    "        #rinds = (qidx, inds(ψ_cp[jj-1], \"Site\")...)\n",
    "        ###########################################################################################\n",
    "        \n",
    "        YF = ((Ri*T)*H[jj])*dag(prime(G)) \n",
    "        XF[jj-1]*YF |> norm2 |> x -> (res += x) #|> display\n",
    "        \n",
    "        \n",
    "        if(jj < L)\n",
    "            (XF[jj]*R_scale)*Ri |> norm2 |> x -> (res += x) #|> display\n",
    "        end\n",
    "        R_scale = R\n",
    "        Ri = ((Ri*B)*H[jj])*dag(prime(B))\n",
    "        rinds = (qidx, inds(ψ_cp[jj-1], \"Site\")...)\n",
    "    end\n",
    "    \n",
    "    \n",
    "    ###############################################################################\n",
    "    return res\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some testing of the variance on a dens mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full variance before dmrg: 10.15859368932418\n",
      "Smart variance before dmrg: 10.156528928972152\n",
      "Difference: 0.002064760352027406\n",
      "After sweep 1 energy=-25.894126119972 maxlinkdim=4 maxerr=1.55E-15 time=0.043\n",
      "After sweep 2 energy=-26.392955115996 maxlinkdim=16 maxerr=4.50E-16 time=0.082\n",
      "After sweep 3 energy=-26.402989431847 maxlinkdim=55 maxerr=9.85E-11 time=0.258\n",
      "After sweep 4 energy=-26.403015091356 maxlinkdim=76 maxerr=1.00E-10 time=0.563\n",
      "After sweep 5 energy=-26.403015129871 maxlinkdim=77 maxerr=9.99E-11 time=0.682\n",
      "Full variance after dmrg: 6.131722329882905e-8\n",
      "Smart variance after dmrg: 6.132357022516837e-8\n",
      "Difference: 6.3469263393232186e-12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "N = 60\n",
    "sites = siteinds(\"S=1/2\",N);\n",
    "psi0 = randomMPS(sites,1);\n",
    "ampo = OpSum()\n",
    "for j=1:N-1\n",
    "    ampo += 0.5,\"S+\",j,\"S-\",j+1\n",
    "    ampo += 0.5,\"S-\",j,\"S+\",j+1\n",
    "    ampo += \"Sz\",j,\"Sz\",j+1\n",
    "end\n",
    "H = MPO(ampo,sites);\n",
    "sweeps = Sweeps(5) # number of sweeps is 5\n",
    "maxdim!(sweeps,10,20,100,100,100,200) # gradually increase states kept\n",
    "    \n",
    "cutoff!(sweeps,1E-10) # desired truncation error\n",
    "#psi0 = copy(psi)\n",
    "full_var_0  = calc_var(psi0,H;full_var = true)\n",
    "println(\"Full variance before dmrg: \",full_var_0)\n",
    "smart_var_0 = calc_var(psi0,H;full_var = false)\n",
    "println(\"Smart variance before dmrg: \",smart_var_0)\n",
    "println(\"Difference: \", abs(full_var_0 - smart_var_0))\n",
    "    \n",
    "energy,psi = dmrg(H,psi0,sweeps);\n",
    "    \n",
    "full_var_1  = calc_var(psi,H;full_var = true)\n",
    "println(\"Full variance after dmrg: \",full_var_1)\n",
    "smart_var_1 = calc_var(psi,H;full_var = false)\n",
    "println(\"Smart variance after dmrg: \",smart_var_1)\n",
    "println(\"Difference: \", abs(full_var_1 - smart_var_1))\n",
    "sz = expect(psi, \"Sz\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  180.025 ms (28483 allocations: 498.46 MiB)\n",
      "  115.259 ms (57514 allocations: 327.19 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.132357022516837e-8"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime calc_var(psi,H;full_var = true)\n",
    "@btime calc_var(psi,H;full_var = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((dim=82|id=383|\"Link,l=30\"), (dim=2|id=968|\"S=1/2,Site,n=30\"), (dim=75|id=376|\"Link,l=29\"))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthogonalize(psi,N÷2)\n",
    "T = psi[N÷2]\n",
    "idxT = inds(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  385.389 μs (131 allocations: 436.33 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime qr(T,idxT[1:2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  509.870 μs (180 allocations: 935.25 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime qr_full(T,idxT[1:2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try to do a qn qr decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the qn of the left/right leg\n",
    "qns = Vector{QN}(undef, 9)\n",
    "for jj in eachindex(qns)\n",
    "    qns[jj] = QN(\"N\", jj - 1)\n",
    "end\n",
    "# creating a left index with qn 0 and 1 and 2, 0 being 1 dim, 1 being 2 dim and 2 being 2 dim\n",
    "j_l  = dag(Index([qns[1] => 1, qns[2] => 2], \"l=1\"));\n",
    "# creating a site index with 0 and 1 qn both being 1 dim\n",
    "si   = dag(Index([qns[1] => 1, qns[2] =>1], \"Site\";));\n",
    "# creating a right index with the same qn as the left index, but different dimensions\n",
    "j_r = Index([qns[1] => 2, qns[2] => 4, qns[3] => 4], \"l=2,1\");\n",
    "# creating a right index with the same qn as the combination of j_l and si\n",
    "#j_r2 = Index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2s = randomITensor(j_r,j_l)\n",
    "T3s = randomITensor(j_l, si, j_r);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "Q,R,qidx = qr_small(T3s, j_r, si);\n",
    "println(Q*R ≈ T3s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "2.186852714097718e-16\n"
     ]
    }
   ],
   "source": [
    "Q1,Q2,R,qidx,qoidx = qr_full(T3s, j_r, si);\n",
    "println(Q1*R ≈ T3s)\n",
    "println(norm(Q1*dag(Q2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  73.675 μs (875 allocations: 124.48 KiB)\n",
      "  98.732 μs (1221 allocations: 180.50 KiB)\n",
      "  122.906 μs (1235 allocations: 177.94 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime qr_small(T3s,j_r,si);\n",
    "@btime qr_full(T3s, j_r,si)\n",
    "@btime factorize(T3s,j_r,si);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full variance before dmrg: 0.5\n",
      "Smart variance before dmrg: 0.5\n",
      "Difference: 0.0\n",
      "After sweep 1 energy=12.755938432009 maxlinkdim=2 maxerr=9.70E-11 time=8.335\n",
      "After sweep 2 energy=12.753423845688 maxlinkdim=2 maxerr=9.70E-11 time=0.084\n",
      "After sweep 3 energy=12.752428313906 maxlinkdim=2 maxerr=1.39E-17 time=0.082\n",
      "After sweep 4 energy=12.751846156467 maxlinkdim=2 maxerr=1.39E-17 time=0.083\n",
      "After sweep 5 energy=12.751550866698 maxlinkdim=2 maxerr=6.94E-18 time=0.083\n",
      "Full variance after dmrg: 1.1098509560270031e-6\n",
      "Smart variance after dmrg: 1.1098508535422829e-6\n",
      "Difference: 1.0248472026802655e-13\n"
     ]
    }
   ],
   "source": [
    "N = 60\n",
    "sites = siteinds(\"S=1/2\",N; conserve_qns = true);\n",
    "#states = [isodd(jj) ? \"Up\" : \"Dn\" for jj in 1:N]\n",
    "states = [\"Up\" for jj in 1:N]\n",
    "states[N÷2] = \"Dn\"\n",
    "psi0 = randomMPS(sites, states,1);\n",
    "ampo = OpSum()\n",
    "for j=1:N-1\n",
    "    ampo += 0.5,\"S+\",j,\"S-\",j+1\n",
    "    ampo += 0.5,\"S-\",j,\"S+\",j+1\n",
    "    ampo += \"Sz\",j,\"Sz\",j+1\n",
    "end\n",
    "H = MPO(ampo,sites);\n",
    "sweeps = Sweeps(5) # number of sweeps is 5\n",
    "maxdim!(sweeps,10,20,100,100,100,200) # gradually increase states kept\n",
    "\n",
    "cutoff!(sweeps,1E-10) # desired truncation error\n",
    "\n",
    "full_var_0  = calc_var(psi0,H;full_var = true)\n",
    "println(\"Full variance before dmrg: \",full_var_0)\n",
    "smart_var_0 = calc_var(psi0,H;full_var = false)\n",
    "println(\"Smart variance before dmrg: \",smart_var_0)\n",
    "println(\"Difference: \", abs(full_var_0 - smart_var_0))\n",
    "    \n",
    "energy,psi = dmrg(H,psi0,sweeps);\n",
    "   \n",
    "full_var_1  = calc_var(psi,H;full_var = true)\n",
    "println(\"Full variance after dmrg: \",full_var_1)\n",
    "smart_var_1 = calc_var(psi,H;full_var = false)\n",
    "println(\"Smart variance after dmrg: \",smart_var_1)\n",
    "println(\"Difference: \", abs(full_var_1 - smart_var_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.117 ms (111032 allocations: 14.03 MiB)\n",
      "  21.056 ms (222834 allocations: 28.20 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1098508535422829e-6"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime calc_var(psi,H;full_var = true)\n",
    "@btime calc_var(psi,H;full_var = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
